# =============================================================================
# Community Events Workflow
# =============================================================================
#
# Checks for recent community events (e.g., football matches, meetups) and
# generates briefings when events are found. Uses providers configured in
# podcast.yaml under triggers.community_events.
#
# Trigger modes:
#   - Cron:           Daily at 06:00 UTC
#   - Manual:         Trigger from GitHub Actions UI (workflow_dispatch)
#   - Reusable:       Other repos can call this via workflow_call
#
# Required secrets:
#   - FOOTBALL_DATA_API_KEY  (for football-data.org provider)
#
# Provider configuration lives in podcast.yaml:
#   triggers:
#     community_events:
#       provider: football-data
#       provider_config:
#         team_id: 73
#         competition_ids: [PL, CL]
#       on_event:
#         briefing:
#           formats: [html, whatsapp]
#           output_dir: reports/briefings
# =============================================================================

name: Community Events

on:
  # --------------------------------------------------------------------------
  # Scheduled trigger: daily at 06:00 UTC
  # --------------------------------------------------------------------------
  schedule:
    - cron: "0 6 * * *"

  # --------------------------------------------------------------------------
  # Manual trigger from Actions UI
  # --------------------------------------------------------------------------
  workflow_dispatch:
    inputs:
      briefing_formats:
        description: "Briefing output formats (comma-separated: html,whatsapp,markdown)"
        required: false
        default: "html,whatsapp"
        type: string
      auto_commit:
        description: "Commit generated briefings to the repository"
        required: false
        default: "false"
        type: boolean

  # --------------------------------------------------------------------------
  # Reusable workflow -- private repos can call this with workflow_call
  # --------------------------------------------------------------------------
  workflow_call:
    inputs:
      briefing_formats:
        description: "Briefing output formats (comma-separated)"
        required: false
        default: "html,whatsapp"
        type: string
      auto_commit:
        description: "Commit generated briefings to the repository"
        required: false
        default: false
        type: boolean
    secrets:
      FOOTBALL_DATA_API_KEY:
        description: "API key for football-data.org provider"
        required: false

# ---------------------------------------------------------------------------
# Permissions: write access for auto-commit and artifact upload
# ---------------------------------------------------------------------------
permissions:
  contents: write
  actions: write

# ---------------------------------------------------------------------------
# Prevent overlapping runs
# ---------------------------------------------------------------------------
concurrency:
  group: community-events-${{ github.ref }}
  cancel-in-progress: true

jobs:
  events:
    name: Check Events & Generate Briefings
    runs-on: ubuntu-latest
    timeout-minutes: 10

    # Map secrets to environment variables
    env:
      FOOTBALL_DATA_API_KEY: ${{ secrets.FOOTBALL_DATA_API_KEY || '' }}
      # Auto-commit controlled by input or env var
      AUTO_COMMIT_BRIEFINGS: ${{ inputs.auto_commit || 'false' }}

    outputs:
      has_events: ${{ steps.check.outputs.has_events }}
      event_count: ${{ steps.check.outputs.event_count }}
      briefings_generated: ${{ steps.briefing.outputs.generated }}

    steps:
      # -----------------------------------------------------------------------
      # 1. Checkout repository (full history for auto-commit)
      # -----------------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Full depth needed if we auto-commit briefings
          fetch-depth: 0

      # -----------------------------------------------------------------------
      # 2. Setup Python 3.12
      # -----------------------------------------------------------------------
      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      # -----------------------------------------------------------------------
      # 3. Install podcast-intel with all optional dependencies
      # -----------------------------------------------------------------------
      - name: Install podcast-intel
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[all]"

      # -----------------------------------------------------------------------
      # 4. Check for recent community events
      # -----------------------------------------------------------------------
      - name: Check for recent events
        id: check
        run: |
          set +e

          # Run the events check command with JSON output
          RESULT=$(python -m podcast_intel.cli events check --output-json 2>&1)
          EXIT_CODE=$?

          # Save full result for artifact upload
          echo "$RESULT" > events-result.json

          # Parse event information from JSON
          HAS_EVENTS=$(echo "$RESULT" | python -c "import sys,json; d=json.load(sys.stdin); print(str(d.get('has_events', False)).lower())" 2>/dev/null || echo "false")
          EVENT_COUNT=$(echo "$RESULT" | python -c "import sys,json; d=json.load(sys.stdin); print(len(d.get('events', [])))" 2>/dev/null || echo "0")
          PROVIDER=$(echo "$RESULT" | python -c "import sys,json; d=json.load(sys.stdin); print(d.get('provider_name', 'unknown'))" 2>/dev/null || echo "unknown")

          # Set outputs
          echo "has_events=$HAS_EVENTS" >> "$GITHUB_OUTPUT"
          echo "event_count=$EVENT_COUNT" >> "$GITHUB_OUTPUT"
          echo "provider=$PROVIDER" >> "$GITHUB_OUTPUT"

          echo "::notice::Events check: has_events=$HAS_EVENTS, count=$EVENT_COUNT, provider=$PROVIDER"

          if [ $EXIT_CODE -ne 0 ]; then
            echo "::warning::Events check exited with code $EXIT_CODE"
          fi

      # -----------------------------------------------------------------------
      # 5. Generate briefings if events were found
      # -----------------------------------------------------------------------
      - name: Generate briefings
        id: briefing
        if: steps.check.outputs.has_events == 'true'
        run: |
          # Determine formats from input or default
          FORMATS="${{ inputs.briefing_formats || 'html,whatsapp' }}"

          echo "Generating briefings in formats: $FORMATS"

          # Run briefing generation
          python -m podcast_intel.cli events briefing --formats "$FORMATS" 2>&1 | tee briefing-output.txt
          EXIT_CODE=${PIPESTATUS[0]}

          if [ $EXIT_CODE -eq 0 ]; then
            echo "generated=true" >> "$GITHUB_OUTPUT"
            echo "::notice::Briefings generated successfully."
          else
            echo "generated=false" >> "$GITHUB_OUTPUT"
            echo "::warning::Briefing generation exited with code $EXIT_CODE"
          fi

      # -----------------------------------------------------------------------
      # 6. Upload briefings as artifacts
      # -----------------------------------------------------------------------
      - name: Upload event results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: events-result
          path: events-result.json
          retention-days: 30

      - name: Upload briefings
        if: steps.briefing.outputs.generated == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: event-briefings
          path: |
            reports/briefings/
          retention-days: 90
          if-no-files-found: ignore

      # -----------------------------------------------------------------------
      # 7. Auto-commit briefings (optional, controlled by input/env var)
      # -----------------------------------------------------------------------
      - name: Commit briefings to repository
        if: |
          steps.briefing.outputs.generated == 'true' &&
          env.AUTO_COMMIT_BRIEFINGS == 'true'
        run: |
          # Configure git for the GitHub Actions bot
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Stage briefing files
          git add reports/briefings/ || true

          # Only commit if there are staged changes
          if git diff --cached --quiet; then
            echo "::notice::No new briefing files to commit."
          else
            TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")
            git commit -m "chore: auto-generated event briefings ($TIMESTAMP)"
            git push
            echo "::notice::Briefings committed and pushed."
          fi

      # -----------------------------------------------------------------------
      # 8. Create GitHub Actions job summary
      # -----------------------------------------------------------------------
      - name: Create job summary
        if: always()
        run: |
          python - <<'PYEOF'
          import json, os, datetime, glob

          # Load the events result
          try:
              with open("events-result.json", "r") as f:
                  result = json.load(f)
          except Exception:
              result = {}

          summary_lines = []
          summary_lines.append("## Community Events Check")
          summary_lines.append("")
          summary_lines.append(f"**Run time:** {datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}")
          summary_lines.append(f"**Provider:** {result.get('provider_name', 'unknown')}")
          summary_lines.append(f"**Checked at:** {result.get('checked_at', 'N/A')}")
          summary_lines.append("")

          # Events table
          events = result.get("events", [])
          has_events = result.get("has_events", False)

          if has_events and events:
              summary_lines.append(f"### Events Found ({len(events)})")
              summary_lines.append("")
              summary_lines.append("| Status | Summary | Date | Competition |")
              summary_lines.append("|--------|---------|------|-------------|")
              for evt in events:
                  status = evt.get("status", "--")
                  summary = evt.get("summary", "Unknown")
                  date = (evt.get("date", "") or "")[:16]
                  comp = evt.get("competition", "--")
                  summary_lines.append(f"| {status} | {summary} | {date} | {comp} |")
              summary_lines.append("")
          else:
              summary_lines.append("No events found.")
              summary_lines.append("")

          # Briefing files generated
          briefing_files = glob.glob("reports/briefings/**/*", recursive=True)
          briefing_files = [f for f in briefing_files if os.path.isfile(f)]
          if briefing_files:
              summary_lines.append("### Generated Briefings")
              summary_lines.append("")
              for bf in briefing_files:
                  summary_lines.append(f"- `{bf}`")
              summary_lines.append("")

          # Errors
          errors = result.get("errors", [])
          if errors:
              summary_lines.append("### Errors")
              summary_lines.append("")
              for err in errors:
                  summary_lines.append(f"- {err}")
              summary_lines.append("")

          # Write summary
          summary_path = os.environ.get("GITHUB_STEP_SUMMARY", "/dev/null")
          with open(summary_path, "a") as f:
              f.write("\n".join(summary_lines))
          PYEOF
